{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "from collections import Counter\n",
    "import joblib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Bidirectional, LSTM\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from nltk.corpus import stopwords\n",
    "from parsivar import Normalizer\n",
    "import emoji\n",
    "import emojies\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class CleanText:\n",
    "    def __init__(self, data_frame, column_name):\n",
    "        self.cln_list = data_frame[column_name].tolist()\n",
    "    def __new__(cls, data_frame, column_name,*args, **kwargs):\n",
    "        data_frame[column_name] = data_frame[column_name].apply(lambda x: x[:400])\n",
    "        return super().__new__(cls,*args, **kwargs)\n",
    "    def clean_punctual(self):\n",
    "        tmp_lst = list(map(lambda x: re.sub(r'https?:\\S*', ' ', x), self.cln_list))\n",
    "        tmp_lst = list(map(lambda x: re.sub(r'@[A-Za-z0-9]\\S+', ' ', x), tmp_lst))\n",
    "        tmp_lst = list(map(lambda x: re.sub(r'[0-9]\\S+', ' ', x), tmp_lst))\n",
    "        self.cln_list = list(map(lambda x: re.sub(r'#|_|:|/d+', ' ', x), tmp_lst))\n",
    "        return self.cln_list\n",
    "    def normalize_text(self):\n",
    "        normalizer = Normalizer(pinglish_conversion_needed=True)\n",
    "        cln_list = list(map(lambda x: normalizer.normalize(x), self.cln_list))\n",
    "        self.cln_list = list(map(lambda x: ''.join(ch for ch, _ in itertools.groupby(x)), cln_list))\n",
    "        return self.cln_list\n",
    "    def remove_stop_words(self):\n",
    "        stop_words = set(stopwords.words('RD_persian_01'))\n",
    "        self.cln_list = list(map(lambda x: ' '.join([w for w in x.split() if not w in stop_words]), self.cln_list))\n",
    "        return self.cln_list\n",
    "    def extract_emojis(self):\n",
    "        self.cln_list = list(map(lambda x: ''.join((' '+c+' ') if c in emoji.UNICODE_EMOJI['en'] else c for c in x), self.cln_list))\n",
    "        return self.cln_list\n",
    "    def convert_emojies(self):\n",
    "        self.cln_list = list(map(lambda x: emojies.replace(x), self.cln_list))\n",
    "        return self.cln_list\n",
    "    def frequency_words(self):\n",
    "        freq = dict(Counter(\" \".join(self.cln_list).split()))\n",
    "        sort_orders = sorted(freq.items(), key=lambda x: x[1], reverse=True)\n",
    "        sort_orders = sort_orders[:4000]\n",
    "        # print(sort_orders)\n",
    "        print(len(sort_orders))\n",
    "        most_common_word = [i[0] for i in sort_orders]\n",
    "        most_common_word = set(most_common_word)\n",
    "        # print(most_common_word)\n",
    "        print(len(most_common_word))\n",
    "        self.cln_list = list(map(lambda x: ' '.join([w for w in x.split() if w in most_common_word]), self.cln_list))\n",
    "        return self.cln_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class EncodeText:\n",
    "    def __init__(self,train_text):\n",
    "        self.train_text = train_text\n",
    "    def create_tokenizer(self):\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(self.train_text)\n",
    "        return tokenizer\n",
    "    def encode_text(self,tokenizer, input_list, max_length):\n",
    "        # integer encode\n",
    "        encoded = tokenizer.texts_to_sequences(input_list)\n",
    "        # pad encoded sequences\n",
    "        padded = pad_sequences(encoded, maxlen=max_length, padding='post')\n",
    "        return padded\n",
    "    def label_encoder(self, tag):\n",
    "        le = LabelEncoder()\n",
    "        tmp_tag = le.fit_transform(tag)\n",
    "        encode_tag = to_categorical(np.array(tmp_tag))\n",
    "        return encode_tag"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# data_df = pd.read_excel('dataset.2.0.0.xlsx', index_col= False)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.hist(data_df['احساس'])\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df = pd.read_csv('comp_dataset2.csv', index_col= False)\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(data_df['tag'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "همسر من تو سکو نفتی کار می کنه ماموریت طولانی مدت می ره همه کارا رو دوش منه الان که مهد کودک تعطیل شده زندگی مثل جهنم شده\n",
      "همسر من تو سکو نفتی کار می کنه ماموریت طولانی مدت می ره همه کارا رو دوش منه الان که مهد کودک تعطیل شده زندگی مثل جهنم شده\n",
      "همسر من تو سکو نفتی کار می کنه ماموریت طولانی مدت می ره همه کارا رو دوش منه الان که مهد کودک تعطیل شده زندگی مثل جهنم شده\n",
      "همسر من تو سکو نفتی کار می‌کنه ماموریت طولانی مدت می‌ره همه کارا رو دوش منه الان که مهد کودک تعطیل‌شده‌زندگی مثل جهنم شده\n",
      "همسر سکو نفتی می‌کنه ماموریت طولانی مدت می‌ره کارا منه الان مهد کودک تعطیل‌شده‌زندگی جهنم شده\n",
      "4000\n",
      "4000\n",
      "همسر می‌کنه طولانی مدت کارا منه الان کودک جهنم شده\n"
     ]
    }
   ],
   "source": [
    "# call_cleantext = CleanText(data_df, 'متن توییت')\n",
    "# call_cleantext = CleanText(data_df, 'Text')\n",
    "call_cleantext = CleanText(data_df, 'caption')\n",
    "get_pun_list = call_cleantext.clean_punctual()\n",
    "print(get_pun_list[64])\n",
    "get_ex_emoji = call_cleantext.extract_emojis()\n",
    "print(get_ex_emoji[64])\n",
    "get_emoji_list = call_cleantext.convert_emojies()\n",
    "print(get_emoji_list[64])\n",
    "get_norm_list = call_cleantext.normalize_text()\n",
    "print(get_norm_list[64])\n",
    "get_rm_sw_list = call_cleantext.remove_stop_words()\n",
    "print(get_rm_sw_list[64])\n",
    "get_most_com_list = call_cleantext.frequency_words()\n",
    "print(get_most_com_list[64])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "get_most_com_list = call_cleantext.frequency_words()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# init_List_prepared = list(map(lambda x: [x[0], x[1]], zip(get_most_com_list, data_df['احساس'])))\n",
    "init_List_prepared = list(map(lambda x: [x[0], x[1]], zip(get_most_com_list, data_df['tag'])))\n",
    "init_List_prepared = list(filter(lambda x: len(x[0])>1, init_List_prepared))\n",
    "random.shuffle(init_List_prepared)\n",
    "\n",
    "var1 = list(filter(lambda x: x[1]=='شادی', init_List_prepared))\n",
    "var2 = list(filter(lambda x: x[1]=='خشم', init_List_prepared))\n",
    "var3 = list(filter(lambda x: x[1]=='غم', init_List_prepared))\n",
    "var4 = list(filter(lambda x: x[1]=='خنثی', init_List_prepared))\n",
    "var5 = list(filter(lambda x: x[1]=='امید', init_List_prepared))\n",
    "var6 = list(filter(lambda x: x[1]=='ترس', init_List_prepared))\n",
    "var7 = list(filter(lambda x: x[1]=='تعجب', init_List_prepared))\n",
    "var8 = list(filter(lambda x: x[1]=='تحسین یا اعتماد', init_List_prepared))\n",
    "\n",
    "# List_prepared = var1[:1500]+var2[:1500]+var3[:1000]+var4[:1000]+var5[:1200]+var6[:700]+var7[:500]+var8[:1500]\n",
    "# List_prepared = var1[:500]+var2[:500]+var3[:500]+var4[:500]+var5[:500]+var6[:500]+var7[:500]+var8[:500]\n",
    "# List_prepared = var1[:2700]+var2[:2700]\n",
    "# List_prepared = var1+var2+var5+var8\n",
    "List_prepared = var1+var2+var3+var5\n",
    "\n",
    "# List_prepared = init_List_prepared"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "text, tag = zip(*List_prepared)\n",
    "train_text, test_text, train_tag, test_tag = train_test_split(text, tag, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% train & test split\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3731\n"
     ]
    }
   ],
   "source": [
    "call_encodetext = EncodeText(train_text)\n",
    "tokenizer = call_encodetext.create_tokenizer()\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)\n",
    "max_len = 100\n",
    "encode_train_text = call_encodetext.encode_text(tokenizer, train_text, max_len)\n",
    "encode_test_text = call_encodetext.encode_text(tokenizer, test_text, max_len)\n",
    "encode_train_tag = call_encodetext.label_encoder(train_tag)\n",
    "encode_test_tag = call_encodetext.label_encoder(test_tag)\n",
    "num_cat = encode_train_tag.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 50)           186550    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              120800    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4)                 804       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 308,154\n",
      "Trainable params: 308,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# single Bidir layer\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 50, input_length=max_len))\n",
    "model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.3)))\n",
    "# model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.3)))\n",
    "model.add(Dense(num_cat, activation='softmax'))\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "209/209 - 29s - loss: 1.0318 - accuracy: 0.5677 - 29s/epoch - 138ms/step\n",
      "Epoch 2/100\n",
      "209/209 - 25s - loss: 0.6348 - accuracy: 0.7640 - 25s/epoch - 119ms/step\n",
      "Epoch 3/100\n",
      "209/209 - 25s - loss: 0.4480 - accuracy: 0.8377 - 25s/epoch - 119ms/step\n",
      "Epoch 4/100\n",
      "209/209 - 25s - loss: 0.3426 - accuracy: 0.8818 - 25s/epoch - 119ms/step\n",
      "Epoch 5/100\n",
      "209/209 - 25s - loss: 0.2769 - accuracy: 0.9020 - 25s/epoch - 119ms/step\n",
      "Epoch 6/100\n",
      "209/209 - 25s - loss: 0.2295 - accuracy: 0.9219 - 25s/epoch - 119ms/step\n",
      "Epoch 7/100\n",
      "209/209 - 25s - loss: 0.2120 - accuracy: 0.9278 - 25s/epoch - 120ms/step\n",
      "Epoch 8/100\n",
      "209/209 - 25s - loss: 0.1759 - accuracy: 0.9428 - 25s/epoch - 119ms/step\n",
      "Epoch 9/100\n",
      "209/209 - 25s - loss: 0.1582 - accuracy: 0.9462 - 25s/epoch - 120ms/step\n",
      "Epoch 10/100\n",
      "209/209 - 26s - loss: 0.1491 - accuracy: 0.9513 - 26s/epoch - 124ms/step\n",
      "Epoch 11/100\n",
      "209/209 - 26s - loss: 0.1412 - accuracy: 0.9520 - 26s/epoch - 123ms/step\n",
      "Epoch 12/100\n",
      "209/209 - 25s - loss: 0.1275 - accuracy: 0.9585 - 25s/epoch - 120ms/step\n",
      "Epoch 13/100\n",
      "209/209 - 25s - loss: 0.1187 - accuracy: 0.9627 - 25s/epoch - 121ms/step\n",
      "Epoch 14/100\n",
      "209/209 - 25s - loss: 0.1112 - accuracy: 0.9630 - 25s/epoch - 120ms/step\n",
      "Epoch 15/100\n",
      "209/209 - 25s - loss: 0.1032 - accuracy: 0.9658 - 25s/epoch - 120ms/step\n",
      "Epoch 16/100\n",
      "209/209 - 25s - loss: 0.0893 - accuracy: 0.9709 - 25s/epoch - 120ms/step\n",
      "Epoch 17/100\n",
      "209/209 - 25s - loss: 0.0883 - accuracy: 0.9708 - 25s/epoch - 119ms/step\n",
      "Epoch 18/100\n",
      "209/209 - 25s - loss: 0.0816 - accuracy: 0.9727 - 25s/epoch - 119ms/step\n",
      "Epoch 19/100\n",
      "209/209 - 25s - loss: 0.0782 - accuracy: 0.9729 - 25s/epoch - 120ms/step\n",
      "Epoch 20/100\n",
      "209/209 - 25s - loss: 0.0788 - accuracy: 0.9729 - 25s/epoch - 119ms/step\n",
      "Epoch 21/100\n",
      "209/209 - 25s - loss: 0.0707 - accuracy: 0.9757 - 25s/epoch - 120ms/step\n",
      "Epoch 22/100\n",
      "209/209 - 25s - loss: 0.0693 - accuracy: 0.9780 - 25s/epoch - 120ms/step\n",
      "Epoch 23/100\n",
      "209/209 - 25s - loss: 0.0702 - accuracy: 0.9760 - 25s/epoch - 120ms/step\n",
      "Epoch 24/100\n",
      "209/209 - 25s - loss: 0.0649 - accuracy: 0.9771 - 25s/epoch - 119ms/step\n",
      "Epoch 25/100\n",
      "209/209 - 25s - loss: 0.0601 - accuracy: 0.9799 - 25s/epoch - 120ms/step\n",
      "Epoch 26/100\n",
      "209/209 - 25s - loss: 0.0554 - accuracy: 0.9814 - 25s/epoch - 119ms/step\n",
      "Epoch 27/100\n",
      "209/209 - 25s - loss: 0.0585 - accuracy: 0.9804 - 25s/epoch - 120ms/step\n",
      "Epoch 28/100\n",
      "209/209 - 25s - loss: 0.0493 - accuracy: 0.9820 - 25s/epoch - 121ms/step\n",
      "Epoch 29/100\n",
      "209/209 - 25s - loss: 0.0479 - accuracy: 0.9817 - 25s/epoch - 120ms/step\n",
      "Epoch 30/100\n",
      "209/209 - 25s - loss: 0.0516 - accuracy: 0.9816 - 25s/epoch - 120ms/step\n",
      "Epoch 31/100\n",
      "209/209 - 25s - loss: 0.0520 - accuracy: 0.9823 - 25s/epoch - 120ms/step\n",
      "Epoch 32/100\n",
      "209/209 - 25s - loss: 0.0443 - accuracy: 0.9849 - 25s/epoch - 120ms/step\n",
      "Epoch 33/100\n",
      "209/209 - 25s - loss: 0.0411 - accuracy: 0.9856 - 25s/epoch - 120ms/step\n",
      "Epoch 34/100\n",
      "209/209 - 25s - loss: 0.0415 - accuracy: 0.9864 - 25s/epoch - 120ms/step\n",
      "Epoch 35/100\n",
      "209/209 - 25s - loss: 0.0409 - accuracy: 0.9837 - 25s/epoch - 120ms/step\n",
      "Epoch 36/100\n",
      "209/209 - 25s - loss: 0.0418 - accuracy: 0.9861 - 25s/epoch - 120ms/step\n",
      "Epoch 37/100\n",
      "209/209 - 25s - loss: 0.0410 - accuracy: 0.9846 - 25s/epoch - 120ms/step\n",
      "Epoch 38/100\n",
      "209/209 - 25s - loss: 0.0360 - accuracy: 0.9873 - 25s/epoch - 120ms/step\n",
      "Epoch 39/100\n",
      "209/209 - 25s - loss: 0.0371 - accuracy: 0.9868 - 25s/epoch - 120ms/step\n",
      "Epoch 40/100\n",
      "209/209 - 25s - loss: 0.0357 - accuracy: 0.9867 - 25s/epoch - 121ms/step\n",
      "Epoch 41/100\n",
      "209/209 - 25s - loss: 0.0386 - accuracy: 0.9874 - 25s/epoch - 120ms/step\n",
      "Epoch 42/100\n",
      "209/209 - 25s - loss: 0.0318 - accuracy: 0.9877 - 25s/epoch - 121ms/step\n",
      "Epoch 43/100\n",
      "209/209 - 25s - loss: 0.0294 - accuracy: 0.9891 - 25s/epoch - 121ms/step\n",
      "Epoch 44/100\n",
      "209/209 - 25s - loss: 0.0314 - accuracy: 0.9889 - 25s/epoch - 121ms/step\n",
      "Epoch 45/100\n",
      "209/209 - 25s - loss: 0.0285 - accuracy: 0.9895 - 25s/epoch - 121ms/step\n",
      "Epoch 46/100\n",
      "209/209 - 25s - loss: 0.0325 - accuracy: 0.9876 - 25s/epoch - 121ms/step\n",
      "Epoch 47/100\n",
      "209/209 - 25s - loss: 0.0319 - accuracy: 0.9882 - 25s/epoch - 121ms/step\n",
      "Epoch 48/100\n",
      "209/209 - 25s - loss: 0.0313 - accuracy: 0.9892 - 25s/epoch - 121ms/step\n",
      "Epoch 49/100\n",
      "209/209 - 25s - loss: 0.0349 - accuracy: 0.9865 - 25s/epoch - 121ms/step\n",
      "Epoch 50/100\n",
      "209/209 - 25s - loss: 0.0365 - accuracy: 0.9870 - 25s/epoch - 121ms/step\n",
      "Epoch 51/100\n",
      "209/209 - 25s - loss: 0.0292 - accuracy: 0.9886 - 25s/epoch - 121ms/step\n",
      "Epoch 52/100\n",
      "209/209 - 25s - loss: 0.0277 - accuracy: 0.9898 - 25s/epoch - 121ms/step\n",
      "Epoch 53/100\n",
      "209/209 - 25s - loss: 0.0258 - accuracy: 0.9901 - 25s/epoch - 121ms/step\n",
      "Epoch 54/100\n",
      "209/209 - 25s - loss: 0.0228 - accuracy: 0.9912 - 25s/epoch - 121ms/step\n",
      "Epoch 55/100\n",
      "209/209 - 25s - loss: 0.0376 - accuracy: 0.9864 - 25s/epoch - 121ms/step\n",
      "Epoch 56/100\n",
      "209/209 - 25s - loss: 0.0266 - accuracy: 0.9913 - 25s/epoch - 121ms/step\n",
      "Epoch 57/100\n",
      "209/209 - 25s - loss: 0.0250 - accuracy: 0.9898 - 25s/epoch - 121ms/step\n",
      "Epoch 58/100\n",
      "209/209 - 25s - loss: 0.0252 - accuracy: 0.9915 - 25s/epoch - 122ms/step\n",
      "Epoch 59/100\n",
      "209/209 - 26s - loss: 0.0235 - accuracy: 0.9915 - 26s/epoch - 122ms/step\n",
      "Epoch 60/100\n",
      "209/209 - 25s - loss: 0.0224 - accuracy: 0.9910 - 25s/epoch - 122ms/step\n",
      "Epoch 61/100\n",
      "209/209 - 25s - loss: 0.0248 - accuracy: 0.9892 - 25s/epoch - 121ms/step\n",
      "Epoch 62/100\n",
      "209/209 - 25s - loss: 0.0231 - accuracy: 0.9921 - 25s/epoch - 121ms/step\n",
      "Epoch 63/100\n",
      "209/209 - 25s - loss: 0.0215 - accuracy: 0.9925 - 25s/epoch - 121ms/step\n",
      "Epoch 64/100\n",
      "209/209 - 25s - loss: 0.0373 - accuracy: 0.9880 - 25s/epoch - 121ms/step\n",
      "Epoch 65/100\n",
      "209/209 - 25s - loss: 0.0215 - accuracy: 0.9909 - 25s/epoch - 121ms/step\n",
      "Epoch 66/100\n",
      "209/209 - 25s - loss: 0.0207 - accuracy: 0.9924 - 25s/epoch - 121ms/step\n",
      "Epoch 67/100\n",
      "209/209 - 25s - loss: 0.0196 - accuracy: 0.9913 - 25s/epoch - 121ms/step\n",
      "Epoch 68/100\n",
      "209/209 - 25s - loss: 0.0178 - accuracy: 0.9928 - 25s/epoch - 121ms/step\n",
      "Epoch 69/100\n",
      "209/209 - 25s - loss: 0.0232 - accuracy: 0.9912 - 25s/epoch - 121ms/step\n",
      "Epoch 70/100\n",
      "209/209 - 25s - loss: 0.0271 - accuracy: 0.9903 - 25s/epoch - 121ms/step\n",
      "Epoch 71/100\n",
      "209/209 - 25s - loss: 0.0215 - accuracy: 0.9927 - 25s/epoch - 121ms/step\n",
      "Epoch 72/100\n",
      "209/209 - 25s - loss: 0.0235 - accuracy: 0.9907 - 25s/epoch - 121ms/step\n",
      "Epoch 73/100\n",
      "209/209 - 25s - loss: 0.0206 - accuracy: 0.9919 - 25s/epoch - 121ms/step\n",
      "Epoch 74/100\n",
      "209/209 - 25s - loss: 0.0225 - accuracy: 0.9916 - 25s/epoch - 121ms/step\n",
      "Epoch 75/100\n",
      "209/209 - 25s - loss: 0.0192 - accuracy: 0.9928 - 25s/epoch - 121ms/step\n",
      "Epoch 76/100\n",
      "209/209 - 25s - loss: 0.0170 - accuracy: 0.9933 - 25s/epoch - 122ms/step\n",
      "Epoch 77/100\n",
      "209/209 - 25s - loss: 0.0175 - accuracy: 0.9933 - 25s/epoch - 121ms/step\n",
      "Epoch 78/100\n",
      "209/209 - 26s - loss: 0.0193 - accuracy: 0.9925 - 26s/epoch - 122ms/step\n",
      "Epoch 79/100\n",
      "209/209 - 25s - loss: 0.0183 - accuracy: 0.9924 - 25s/epoch - 122ms/step\n",
      "Epoch 80/100\n",
      "209/209 - 25s - loss: 0.0216 - accuracy: 0.9921 - 25s/epoch - 121ms/step\n",
      "Epoch 81/100\n",
      "209/209 - 25s - loss: 0.0180 - accuracy: 0.9924 - 25s/epoch - 122ms/step\n",
      "Epoch 82/100\n",
      "209/209 - 25s - loss: 0.0252 - accuracy: 0.9921 - 25s/epoch - 122ms/step\n",
      "Epoch 83/100\n",
      "209/209 - 26s - loss: 0.0176 - accuracy: 0.9933 - 26s/epoch - 122ms/step\n",
      "Epoch 84/100\n",
      "209/209 - 25s - loss: 0.0185 - accuracy: 0.9925 - 25s/epoch - 122ms/step\n",
      "Epoch 85/100\n",
      "209/209 - 26s - loss: 0.0245 - accuracy: 0.9915 - 26s/epoch - 122ms/step\n",
      "Epoch 86/100\n",
      "209/209 - 25s - loss: 0.0170 - accuracy: 0.9927 - 25s/epoch - 122ms/step\n",
      "Epoch 87/100\n",
      "209/209 - 26s - loss: 0.0166 - accuracy: 0.9937 - 26s/epoch - 122ms/step\n",
      "Epoch 88/100\n",
      "209/209 - 25s - loss: 0.0202 - accuracy: 0.9921 - 25s/epoch - 122ms/step\n",
      "Epoch 89/100\n",
      "209/209 - 25s - loss: 0.0156 - accuracy: 0.9940 - 25s/epoch - 122ms/step\n",
      "Epoch 90/100\n",
      "209/209 - 25s - loss: 0.0158 - accuracy: 0.9936 - 25s/epoch - 121ms/step\n",
      "Epoch 91/100\n",
      "209/209 - 26s - loss: 0.0160 - accuracy: 0.9934 - 26s/epoch - 122ms/step\n",
      "Epoch 92/100\n",
      "209/209 - 26s - loss: 0.0250 - accuracy: 0.9910 - 26s/epoch - 122ms/step\n",
      "Epoch 93/100\n",
      "209/209 - 25s - loss: 0.0234 - accuracy: 0.9907 - 25s/epoch - 122ms/step\n",
      "Epoch 94/100\n",
      "209/209 - 26s - loss: 0.0173 - accuracy: 0.9928 - 26s/epoch - 123ms/step\n",
      "Epoch 95/100\n",
      "209/209 - 26s - loss: 0.0160 - accuracy: 0.9931 - 26s/epoch - 122ms/step\n",
      "Epoch 96/100\n",
      "209/209 - 26s - loss: 0.0175 - accuracy: 0.9934 - 26s/epoch - 122ms/step\n",
      "Epoch 97/100\n",
      "209/209 - 26s - loss: 0.0144 - accuracy: 0.9939 - 26s/epoch - 122ms/step\n",
      "Epoch 98/100\n",
      "209/209 - 25s - loss: 0.0171 - accuracy: 0.9922 - 25s/epoch - 122ms/step\n",
      "Epoch 99/100\n",
      "209/209 - 26s - loss: 0.0145 - accuracy: 0.9937 - 26s/epoch - 123ms/step\n",
      "Epoch 100/100\n",
      "209/209 - 26s - loss: 0.0214 - accuracy: 0.9901 - 26s/epoch - 123ms/step\n",
      "Test Accuracy: 70.461357\n",
      "Test loss: 2.649911\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fitting Network\n",
    "m = model.fit(encode_train_text, encode_train_tag, epochs=100, verbose=2)\n",
    "# Evaluating Network\n",
    "loss, acc = model.evaluate(encode_test_text, encode_test_tag, verbose=0)\n",
    "print('Test Accuracy: %f' % (acc * 100))\n",
    "print('Test loss: %f' % loss)\n",
    "# !khashm, khonsa, shadi, gham of 1e4 51%"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://7301ea02-e95e-4f5a-9f87-9e3c50b42168/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000024DB561E978> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000024DB62C13C8> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/plain": "['BiLSTM_3_model.joblib']"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('BiLSTM_3_tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# # # loading\n",
    "# # with open('BiLSTM_3_tokenizer.pickle', 'rb') as handle:\n",
    "# #     tokenizer = pickle.load(handle)\n",
    "joblib.dump(model, 'BiLSTM_3_model.joblib')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% save model\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# test_df = pd.DataFrame()\n",
    "# test_df['train_text'] = train_text\n",
    "# test_df['tag_text'] = train_tag\n",
    "# test_df['encode_train_tag'] = encode_train_tag.tolist()\n",
    "# test_df.to_excel('test2_df.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Evaluate test file\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# tmp_df = pd.DataFrame()\n",
    "# comment = train_text\n",
    "# tmp_df['tmp_caption']=comment\n",
    "# print(tmp_df)\n",
    "# tmp_call_cleantext = CleanText(tmp_df, 'tmp_caption')\n",
    "# tmp_get_ex_emoji = tmp_call_cleantext.extract_emojis()\n",
    "# print(tmp_get_ex_emoji)\n",
    "# tmp_get_emoji_list = tmp_call_cleantext.convert_emojies()\n",
    "# tmp_get_norm_list = tmp_call_cleantext.normalize_text()\n",
    "# print(tmp_get_norm_list)\n",
    "#\n",
    "# list_a = []\n",
    "# i = 0\n",
    "# for item in tmp_get_norm_list:\n",
    "#     i += 1\n",
    "#     # print(i)\n",
    "#     comment_list = item\n",
    "#     instance = tokenizer.texts_to_sequences(comment_list)\n",
    "#     flat_list = []\n",
    "#     for sublist in instance:\n",
    "#         for item in sublist:\n",
    "#             flat_list.append(item)\n",
    "#\n",
    "#     flat_list = [flat_list]\n",
    "#\n",
    "#     instance = pad_sequences(flat_list, padding='post', maxlen=max_len)\n",
    "#\n",
    "#     output = model.predict(instance)\n",
    "#     list_a.append(output)\n",
    "# # print(list_a)\n",
    "# train_df = pd.DataFrame()\n",
    "# train_df['train_text'] = train_text\n",
    "# train_df['tag_text'] = train_tag\n",
    "# train_df['encode_train_tag'] = encode_train_tag.tolist()\n",
    "# train_df['my_model'] = list_a\n",
    "# train_df.to_excel('train2_df.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Evaluate train file\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# df = pd.read_excel('train2_df.xlsx')\n",
    "# list_b = df['my_model']\n",
    "# list_c = list(map(lambda x: list(x[2:-2].split(\" \")), list_b))\n",
    "# list_c = list(map(lambda x: list(filter(None, x)), list_c))\n",
    "#\n",
    "# list_d = list(map(lambda x: [re.sub('\\n','', i) for i in x], list_c))\n",
    "#\n",
    "# list_e = list(map(lambda x: [float(i) for i in x], list_d))\n",
    "# list_f = list(map(lambda x: x.index(max(x)), list_e))\n",
    "# train_df['my_model2'] = list_f\n",
    "# train_df.to_excel('train2_df.xlsx', index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}