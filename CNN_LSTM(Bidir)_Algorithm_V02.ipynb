{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "from collections import Counter\n",
    "import joblib\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Bidirectional, LSTM\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from nltk.corpus import stopwords\n",
    "from parsivar import Normalizer\n",
    "import emoji\n",
    "import emojies\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class CleanText:\n",
    "    def __init__(self, data_frame, column_name):\n",
    "        self.cln_list = data_frame[column_name].tolist()\n",
    "    def __new__(cls, data_frame, column_name,*args, **kwargs):\n",
    "        data_frame[column_name] = data_frame[column_name].apply(lambda x: x[:400])\n",
    "        return super().__new__(cls,*args, **kwargs)\n",
    "    def clean_punctual(self):\n",
    "        tmp_lst = list(map(lambda x: re.sub(r'https?:\\S*', ' ', x), self.cln_list))\n",
    "        tmp_lst = list(map(lambda x: re.sub(r'@[A-Za-z0-9]\\S+', ' ', x), tmp_lst))\n",
    "        tmp_lst = list(map(lambda x: re.sub(r'[0-9]\\S+', ' ', x), tmp_lst))\n",
    "        self.cln_list = list(map(lambda x: re.sub(r'#|_|:|/d+', ' ', x), tmp_lst))\n",
    "        return self.cln_list\n",
    "    def normalize_text(self):\n",
    "        normalizer = Normalizer(pinglish_conversion_needed=True)\n",
    "        cln_list = list(map(lambda x: normalizer.normalize(x), self.cln_list))\n",
    "        self.cln_list = list(map(lambda x: ''.join(ch for ch, _ in itertools.groupby(x)), cln_list))\n",
    "        return self.cln_list\n",
    "    def remove_stop_words(self):\n",
    "        stop_words = set(stopwords.words('RD_persian_01'))\n",
    "        self.cln_list = list(map(lambda x: ' '.join([w for w in x.split() if not w in stop_words]), self.cln_list))\n",
    "        return self.cln_list\n",
    "    def extract_emojis(self):\n",
    "        self.cln_list = list(map(lambda x: ''.join((' '+c+' ') if c in emoji.UNICODE_EMOJI['en'] else c for c in x), self.cln_list))\n",
    "        return self.cln_list\n",
    "    def convert_emojies(self):\n",
    "        self.cln_list = list(map(lambda x: emojies.replace(x), self.cln_list))\n",
    "        return self.cln_list\n",
    "    def frequency_words(self):\n",
    "        freq = dict(Counter(\" \".join(self.cln_list).split()))\n",
    "        sort_orders = sorted(freq.items(), key=lambda x: x[1], reverse=True)\n",
    "        sort_orders = sort_orders[:4000]\n",
    "        # print(sort_orders)\n",
    "        print(len(sort_orders))\n",
    "        most_common_word = [i[0] for i in sort_orders]\n",
    "        most_common_word = set(most_common_word)\n",
    "        # print(most_common_word)\n",
    "        print(len(most_common_word))\n",
    "        self.cln_list = list(map(lambda x: ' '.join([w for w in x.split() if w in most_common_word]), self.cln_list))\n",
    "        return self.cln_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class EncodeText:\n",
    "    def __init__(self,train_text):\n",
    "        self.train_text = train_text\n",
    "    def create_tokenizer(self):\n",
    "        tokenizer = Tokenizer()\n",
    "        tokenizer.fit_on_texts(self.train_text)\n",
    "        return tokenizer\n",
    "    def encode_text(self,tokenizer, input_list, max_length):\n",
    "        # integer encode\n",
    "        encoded = tokenizer.texts_to_sequences(input_list)\n",
    "        # pad encoded sequences\n",
    "        padded = pad_sequences(encoded, maxlen=max_length, padding='post')\n",
    "        return padded\n",
    "    def label_encoder(self, tag):\n",
    "        le = LabelEncoder()\n",
    "        tmp_tag = le.fit_transform(tag)\n",
    "        encode_tag = to_categorical(np.array(tmp_tag))\n",
    "        return encode_tag"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# data_df = pd.read_excel('dataset.2.0.0.xlsx', index_col= False)\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.hist(data_df['احساس'])\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_df = pd.read_csv('comp_dataset2.csv', index_col= False)\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(data_df['tag'])\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "همسر من تو سکو نفتی کار می کنه ماموریت طولانی مدت می ره همه کارا رو دوش منه الان که مهد کودک تعطیل شده زندگی مثل جهنم شده\n",
      "همسر من تو سکو نفتی کار می کنه ماموریت طولانی مدت می ره همه کارا رو دوش منه الان که مهد کودک تعطیل شده زندگی مثل جهنم شده\n",
      "همسر من تو سکو نفتی کار می کنه ماموریت طولانی مدت می ره همه کارا رو دوش منه الان که مهد کودک تعطیل شده زندگی مثل جهنم شده\n",
      "همسر من تو سکو نفتی کار می‌کنه ماموریت طولانی مدت می‌ره همه کارا رو دوش منه الان که مهد کودک تعطیل‌شده‌زندگی مثل جهنم شده\n",
      "همسر سکو نفتی می‌کنه ماموریت طولانی مدت می‌ره کارا منه الان مهد کودک تعطیل‌شده‌زندگی جهنم شده\n",
      "4000\n",
      "4000\n",
      "همسر می‌کنه طولانی مدت کارا منه الان کودک جهنم شده\n"
     ]
    }
   ],
   "source": [
    "# call_cleantext = CleanText(data_df, 'متن توییت')\n",
    "# call_cleantext = CleanText(data_df, 'Text')\n",
    "call_cleantext = CleanText(data_df, 'caption')\n",
    "get_pun_list = call_cleantext.clean_punctual()\n",
    "print(get_pun_list[64])\n",
    "get_ex_emoji = call_cleantext.extract_emojis()\n",
    "print(get_ex_emoji[64])\n",
    "get_emoji_list = call_cleantext.convert_emojies()\n",
    "print(get_emoji_list[64])\n",
    "get_norm_list = call_cleantext.normalize_text()\n",
    "print(get_norm_list[64])\n",
    "get_rm_sw_list = call_cleantext.remove_stop_words()\n",
    "print(get_rm_sw_list[64])\n",
    "get_most_com_list = call_cleantext.frequency_words()\n",
    "print(get_most_com_list[64])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "get_most_com_list = call_cleantext.frequency_words()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# init_List_prepared = list(map(lambda x: [x[0], x[1]], zip(get_most_com_list, data_df['احساس'])))\n",
    "init_List_prepared = list(map(lambda x: [x[0], x[1]], zip(get_most_com_list, data_df['tag'])))\n",
    "init_List_prepared = list(filter(lambda x: len(x[0])>1, init_List_prepared))\n",
    "random.shuffle(init_List_prepared)\n",
    "\n",
    "var1 = list(filter(lambda x: x[1]=='شادی', init_List_prepared))\n",
    "var2 = list(filter(lambda x: x[1]=='خشم', init_List_prepared))\n",
    "var3 = list(filter(lambda x: x[1]=='غم', init_List_prepared))\n",
    "var4 = list(filter(lambda x: x[1]=='خنثی', init_List_prepared))\n",
    "var5 = list(filter(lambda x: x[1]=='امید', init_List_prepared))\n",
    "var6 = list(filter(lambda x: x[1]=='ترس', init_List_prepared))\n",
    "var7 = list(filter(lambda x: x[1]=='تعجب', init_List_prepared))\n",
    "var8 = list(filter(lambda x: x[1]=='تحسین یا اعتماد', init_List_prepared))\n",
    "\n",
    "# List_prepared = var1[:1500]+var2[:1500]+var3[:1000]+var4[:1000]+var5[:1200]+var6[:700]+var7[:500]+var8[:1500]\n",
    "# List_prepared = var1[:500]+var2[:500]+var3[:500]+var4[:500]+var5[:500]+var6[:500]+var7[:500]+var8[:500]\n",
    "# List_prepared = var1[:2700]+var2[:2700]\n",
    "# List_prepared = var1+var2+var5+var8\n",
    "List_prepared = var1[:2000]+var2\n",
    "\n",
    "# List_prepared = init_List_prepared"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "text, tag = zip(*List_prepared)\n",
    "train_text, test_text, train_tag, test_tag = train_test_split(text, tag, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% train & test split\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3323\n"
     ]
    }
   ],
   "source": [
    "call_encodetext = EncodeText(train_text)\n",
    "tokenizer = call_encodetext.create_tokenizer()\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)\n",
    "max_len = 100\n",
    "encode_train_text = call_encodetext.encode_text(tokenizer, train_text, max_len)\n",
    "encode_test_text = call_encodetext.encode_text(tokenizer, test_text, max_len)\n",
    "encode_train_tag = call_encodetext.label_encoder(train_tag)\n",
    "encode_test_tag = call_encodetext.label_encoder(test_tag)\n",
    "num_cat = encode_train_tag.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 100)          332300    \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 93, 32)            25632     \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 46, 32)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 200)              106400    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 20)                4020      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 468,394\n",
      "Trainable params: 468,394\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length=max_len))\n",
    "model.add(Conv1D(filters=32, kernel_size=8, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.3)))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(num_cat, activation='softmax'))\n",
    "print(model.summary())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "117/117 - 12s - loss: 0.5256 - accuracy: 0.7112 - 12s/epoch - 107ms/step\n",
      "Epoch 2/50\n",
      "117/117 - 9s - loss: 0.2385 - accuracy: 0.9050 - 9s/epoch - 80ms/step\n",
      "Epoch 3/50\n",
      "117/117 - 8s - loss: 0.1217 - accuracy: 0.9561 - 8s/epoch - 71ms/step\n",
      "Epoch 4/50\n",
      "117/117 - 8s - loss: 0.0727 - accuracy: 0.9787 - 8s/epoch - 64ms/step\n",
      "Epoch 5/50\n",
      "117/117 - 7s - loss: 0.0491 - accuracy: 0.9841 - 7s/epoch - 64ms/step\n",
      "Epoch 6/50\n",
      "117/117 - 8s - loss: 0.0288 - accuracy: 0.9900 - 8s/epoch - 64ms/step\n",
      "Epoch 7/50\n",
      "117/117 - 8s - loss: 0.0245 - accuracy: 0.9906 - 8s/epoch - 64ms/step\n",
      "Epoch 8/50\n",
      "117/117 - 8s - loss: 0.0172 - accuracy: 0.9946 - 8s/epoch - 64ms/step\n",
      "Epoch 9/50\n",
      "117/117 - 7s - loss: 0.0125 - accuracy: 0.9952 - 7s/epoch - 64ms/step\n",
      "Epoch 10/50\n",
      "117/117 - 8s - loss: 0.0121 - accuracy: 0.9954 - 8s/epoch - 64ms/step\n",
      "Epoch 11/50\n",
      "117/117 - 8s - loss: 0.0168 - accuracy: 0.9946 - 8s/epoch - 65ms/step\n",
      "Epoch 12/50\n",
      "117/117 - 8s - loss: 0.0078 - accuracy: 0.9970 - 8s/epoch - 68ms/step\n",
      "Epoch 13/50\n",
      "117/117 - 10s - loss: 0.0060 - accuracy: 0.9981 - 10s/epoch - 84ms/step\n",
      "Epoch 14/50\n",
      "117/117 - 11s - loss: 0.0056 - accuracy: 0.9981 - 11s/epoch - 91ms/step\n",
      "Epoch 15/50\n",
      "117/117 - 10s - loss: 0.0059 - accuracy: 0.9978 - 10s/epoch - 84ms/step\n",
      "Epoch 16/50\n",
      "117/117 - 9s - loss: 0.0126 - accuracy: 0.9957 - 9s/epoch - 75ms/step\n",
      "Epoch 17/50\n",
      "117/117 - 8s - loss: 0.0086 - accuracy: 0.9968 - 8s/epoch - 71ms/step\n",
      "Epoch 18/50\n",
      "117/117 - 8s - loss: 0.0080 - accuracy: 0.9968 - 8s/epoch - 72ms/step\n",
      "Epoch 19/50\n",
      "117/117 - 8s - loss: 0.0052 - accuracy: 0.9978 - 8s/epoch - 71ms/step\n",
      "Epoch 20/50\n",
      "117/117 - 8s - loss: 0.0046 - accuracy: 0.9984 - 8s/epoch - 71ms/step\n",
      "Epoch 21/50\n",
      "117/117 - 8s - loss: 0.0060 - accuracy: 0.9984 - 8s/epoch - 71ms/step\n",
      "Epoch 22/50\n",
      "117/117 - 8s - loss: 0.0045 - accuracy: 0.9981 - 8s/epoch - 70ms/step\n",
      "Epoch 23/50\n",
      "117/117 - 8s - loss: 0.0051 - accuracy: 0.9981 - 8s/epoch - 69ms/step\n",
      "Epoch 24/50\n",
      "117/117 - 8s - loss: 0.0041 - accuracy: 0.9984 - 8s/epoch - 70ms/step\n",
      "Epoch 25/50\n",
      "117/117 - 9s - loss: 0.0038 - accuracy: 0.9987 - 9s/epoch - 78ms/step\n",
      "Epoch 26/50\n",
      "117/117 - 8s - loss: 0.0051 - accuracy: 0.9981 - 8s/epoch - 72ms/step\n",
      "Epoch 27/50\n",
      "117/117 - 9s - loss: 0.0057 - accuracy: 0.9981 - 9s/epoch - 79ms/step\n",
      "Epoch 28/50\n",
      "117/117 - 15s - loss: 0.0033 - accuracy: 0.9987 - 15s/epoch - 129ms/step\n",
      "Epoch 29/50\n",
      "117/117 - 15s - loss: 0.0042 - accuracy: 0.9981 - 15s/epoch - 128ms/step\n",
      "Epoch 30/50\n",
      "117/117 - 15s - loss: 0.0146 - accuracy: 0.9954 - 15s/epoch - 128ms/step\n",
      "Epoch 31/50\n",
      "117/117 - 15s - loss: 0.0113 - accuracy: 0.9954 - 15s/epoch - 127ms/step\n",
      "Epoch 32/50\n",
      "117/117 - 14s - loss: 0.0085 - accuracy: 0.9962 - 14s/epoch - 120ms/step\n",
      "Epoch 33/50\n",
      "117/117 - 13s - loss: 0.0053 - accuracy: 0.9978 - 13s/epoch - 111ms/step\n",
      "Epoch 34/50\n",
      "117/117 - 14s - loss: 0.0038 - accuracy: 0.9984 - 14s/epoch - 121ms/step\n",
      "Epoch 35/50\n",
      "117/117 - 15s - loss: 0.0044 - accuracy: 0.9981 - 15s/epoch - 126ms/step\n",
      "Epoch 36/50\n",
      "117/117 - 16s - loss: 0.0055 - accuracy: 0.9973 - 16s/epoch - 133ms/step\n",
      "Epoch 37/50\n",
      "117/117 - 14s - loss: 0.0044 - accuracy: 0.9984 - 14s/epoch - 119ms/step\n",
      "Epoch 38/50\n",
      "117/117 - 13s - loss: 0.0041 - accuracy: 0.9987 - 13s/epoch - 114ms/step\n",
      "Epoch 39/50\n",
      "117/117 - 14s - loss: 0.0037 - accuracy: 0.9987 - 14s/epoch - 120ms/step\n",
      "Epoch 40/50\n",
      "117/117 - 14s - loss: 0.0042 - accuracy: 0.9981 - 14s/epoch - 119ms/step\n",
      "Epoch 41/50\n",
      "117/117 - 14s - loss: 0.0039 - accuracy: 0.9987 - 14s/epoch - 116ms/step\n",
      "Epoch 42/50\n",
      "117/117 - 13s - loss: 0.0062 - accuracy: 0.9970 - 13s/epoch - 112ms/step\n",
      "Epoch 43/50\n",
      "117/117 - 13s - loss: 0.0096 - accuracy: 0.9965 - 13s/epoch - 112ms/step\n",
      "Epoch 44/50\n",
      "117/117 - 13s - loss: 0.0037 - accuracy: 0.9984 - 13s/epoch - 111ms/step\n",
      "Epoch 45/50\n",
      "117/117 - 14s - loss: 0.0035 - accuracy: 0.9984 - 14s/epoch - 118ms/step\n",
      "Epoch 46/50\n",
      "117/117 - 15s - loss: 0.0035 - accuracy: 0.9981 - 15s/epoch - 126ms/step\n",
      "Epoch 47/50\n",
      "117/117 - 14s - loss: 0.0036 - accuracy: 0.9981 - 14s/epoch - 120ms/step\n",
      "Epoch 48/50\n",
      "117/117 - 14s - loss: 0.0046 - accuracy: 0.9978 - 14s/epoch - 119ms/step\n",
      "Epoch 49/50\n",
      "117/117 - 14s - loss: 0.0029 - accuracy: 0.9984 - 14s/epoch - 121ms/step\n",
      "Epoch 50/50\n",
      "117/117 - 14s - loss: 0.0029 - accuracy: 0.9989 - 14s/epoch - 119ms/step\n",
      "Test Accuracy: 86.006457\n",
      "Test loss: 1.338860\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fitting Network\n",
    "m = model.fit(encode_train_text, encode_train_tag, epochs=50, verbose=2)\n",
    "# Evaluating Network\n",
    "loss, acc = model.evaluate(encode_test_text, encode_test_tag, verbose=0)\n",
    "print('Test Accuracy: %f' % (acc * 100))\n",
    "print('Test loss: %f' % loss)\n",
    "# !khashm, khonsa, shadi, gham of 1e4 51%"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# with open('CNN_BiLSTM_6_tokenizer.pickle', 'wb') as handle:\n",
    "#     pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# # # loading\n",
    "# # with open('CNN_BiLSTM_6_tokenizer.pickle', 'rb') as handle:\n",
    "# #     tokenizer = pickle.load(handle)\n",
    "# joblib.dump(model, 'CNN_BiLSTM_6_model.joblib')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% save model\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# test_df = pd.DataFrame()\n",
    "# test_df['train_text'] = train_text\n",
    "# test_df['tag_text'] = train_tag\n",
    "# test_df['encode_train_tag'] = encode_train_tag.tolist()\n",
    "# test_df.to_excel('test2_df.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Evaluate test file\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://430ecb59-2f10-4c82-8400-df9d830c692c/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000026617B44668> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000026617A73828> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "data": {
      "text/plain": "['CNN_BiLSTM_6_model.joblib']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tmp_df = pd.DataFrame()\n",
    "# comment = train_text\n",
    "# tmp_df['tmp_caption']=comment\n",
    "# print(tmp_df)\n",
    "# tmp_call_cleantext = CleanText(tmp_df, 'tmp_caption')\n",
    "# tmp_get_ex_emoji = tmp_call_cleantext.extract_emojis()\n",
    "# print(tmp_get_ex_emoji)\n",
    "# tmp_get_emoji_list = tmp_call_cleantext.convert_emojies()\n",
    "# tmp_get_norm_list = tmp_call_cleantext.normalize_text()\n",
    "# print(tmp_get_norm_list)\n",
    "#\n",
    "# list_a = []\n",
    "# i = 0\n",
    "# for item in tmp_get_norm_list:\n",
    "#     i += 1\n",
    "#     # print(i)\n",
    "#     comment_list = item\n",
    "#     instance = tokenizer.texts_to_sequences(comment_list)\n",
    "#     flat_list = []\n",
    "#     for sublist in instance:\n",
    "#         for item in sublist:\n",
    "#             flat_list.append(item)\n",
    "#\n",
    "#     flat_list = [flat_list]\n",
    "#\n",
    "#     instance = pad_sequences(flat_list, padding='post', maxlen=max_len)\n",
    "#\n",
    "#     output = model.predict(instance)\n",
    "#     list_a.append(output)\n",
    "# # print(list_a)\n",
    "# train_df = pd.DataFrame()\n",
    "# train_df['train_text'] = train_text\n",
    "# train_df['tag_text'] = train_tag\n",
    "# train_df['encode_train_tag'] = encode_train_tag.tolist()\n",
    "# train_df['my_model'] = list_a\n",
    "# train_df.to_excel('train2_df.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Evaluate train file\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# df = pd.read_excel('train2_df.xlsx')\n",
    "# list_b = df['my_model']\n",
    "# list_c = list(map(lambda x: list(x[2:-2].split(\" \")), list_b))\n",
    "# list_c = list(map(lambda x: list(filter(None, x)), list_c))\n",
    "#\n",
    "# list_d = list(map(lambda x: [re.sub('\\n','', i) for i in x], list_c))\n",
    "#\n",
    "# list_e = list(map(lambda x: [float(i) for i in x], list_d))\n",
    "# list_f = list(map(lambda x: x.index(max(x)), list_e))\n",
    "# train_df['my_model2'] = list_f\n",
    "# train_df.to_excel('train2_df.xlsx', index=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}